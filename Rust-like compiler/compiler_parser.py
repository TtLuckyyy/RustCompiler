"""è¯­æ³•åˆ†æå™¨"""
from collections import namedtuple, defaultdict
from compiler_lexer import Token
from compiler_parser_node import ParseNode
from compiler_rust_grammar import RUST_GRAMMAR, TEST_GRAMMAR, LEFT_RECURSION_GRAMMAR
from compiler_semantic_checker import SemanticChecker
from compiler_logger import logger
from enum import Enum

# å…ƒç»„å½¢å¼çš„é¡¹ç›®å…ƒç´  Hashable
LR1Item = namedtuple('LR1Item', ['prod_lhs', 'prod_rhs', 'dot_pos', 'lookahead'])

class Parser:
    def __init__(self):
        self._first_cache = {} # firsté›†ç¼“å­˜
        
    def _initialize_grammar(self):
        """åˆå§‹åŒ–è¯­æ³•"""
        self.terminals = set(self.grammar.get('terminals', []))         # ç»ˆç»“ç¬¦
        self.non_terminals = set(self.grammar.get('non_terminals', [])) # éç»ˆç»“ç¬¦
        self.productions = defaultdict(list)                            # é€šè¿‡LHSæŸ¥è¯¢äº§ç”Ÿå¼
        self.prod_by_index = {}                                         # é€šè¿‡ç´¢å¼•æŸ¥æ‰¾äº§ç”Ÿå¼
        self.start_symbol = self.grammar['start_symbol']                # èµ·å§‹ç¬¦å·

        # é¢„å¤„ç†äº§ç”Ÿå¼
        for idx, prod in enumerate(self.grammar['productions']):
            lhs = prod['prod_lhs']  # äº§ç”Ÿå¼å·¦ä¾§
            rhs = prod['prod_rhs']  # äº§ç”Ÿå¼å³ä¾§
            self.non_terminals.add(lhs)
            self.productions[lhs].append({
                'rhs': rhs,
                'index':idx
            })
            self.prod_by_index[idx] = {
                'lhs': lhs,
                'rhs': rhs
            }
        
        # è¾“å‡ºè°ƒè¯•ä¿¡æ¯ï¼šå¤„ç†åçš„è¯­æ³•
        self._log_grammar_info()

    def eliminate_left_recursion(self, grammar):
        """
        æ¶ˆé™¤æ–‡æ³•çš„ç›´æ¥å’Œé—´æ¥å·¦é€’å½’
        æ³¨: å·²ç»ä¸å†éœ€è¦è¿™ä¸ªå‡½æ•°
        """
        logger.info("Starting left recursion elimination...")
        original_count = len(grammar['productions'])
        logger.info(f"Original production count: {original_count}")

        prod_dict = defaultdict(list)
        for prod in grammar['productions']:
            prod_dict[prod['prod_lhs']].append(prod['prod_rhs'])
        
        non_terminals = list(prod_dict.keys())
        new_productions = []

        for i in range(len(non_terminals)):
            Ai = non_terminals[i]
            for j in range(i):
                Aj = non_terminals[j]
                update_rules = []
                for rhs in prod_dict[Ai]:
                    if len(rhs) == 0:
                        update_rules.append(rhs)
                    elif rhs[0] == Aj:
                        # Ai -> Aj Î³, æ›¿æ¢Ajçš„äº§ç”Ÿå¼
                        for gamma in prod_dict[Aj]:
                            update_rules.append(gamma + rhs[1:])
                    else:
                        update_rules.append(rhs)
                prod_dict[Ai] = update_rules

            # æ¶ˆé™¤ç›´æ¥å·¦é€’å½’
            direct_left = []
            non_left = []

            for rhs in prod_dict[Ai]:
                if len(rhs) == 0:
                    non_left.append(rhs)
                elif rhs[0] == Ai:
                    direct_left.append(rhs[1:])
                else:
                    non_left.append(rhs)
            
            if direct_left:
                Ai_prime = Ai + "_tail"
                for beta in non_left:
                    new_productions.append({
                        'prod_lhs': Ai,
                        'prod_rhs': beta + [Ai_prime]
                    })
                for alpha in direct_left:
                    new_productions.append({
                        'prod_lhs': Ai_prime,
                        'prod_rhs': alpha + [Ai_prime]
                    })
                new_productions.append({
                    'prod_lhs': Ai_prime,
                    'prod_rhs': []
                })
            else:
                for rhs in prod_dict[Ai]:
                    new_productions.append({
                        'prod_lhs': Ai,
                        'prod_rhs': rhs
                    })

        grammar['productions'] = new_productions
        new_count = len(grammar['productions'])
        logger.info(f"Left recursion elimination completed.")
        logger.info(f"New production count: {new_count}")
        return grammar

    def closure(self, items):
        """
        è®¡ç®—é¡¹ç›®é›†çš„é—­åŒ…(æ‰©å±•å½“å‰é¡¹ç›®é›†)
        æ ¸å¿ƒæ€æƒ³ï¼šå°†æ‰€æœ‰å¯èƒ½é€šè¿‡ éç»ˆç»“ç¬¦è½¬ç§» è§¦å‘çš„å­é¡¹ç›®çº³å…¥å½“å‰çŠ¶æ€ã€‚
        :param items: é¡¹ç›®é›† [{'production': äº§ç”Ÿå¼, 'dot_pos': ä½ç½®, 'lookahead': å‘å‰çœ‹ç¬¦å·}]
        :return: é—­åŒ…åçš„é¡¹ç›®é›† (LR1Item)
        """
        # å°†é¡¹ç›®é—­åŒ…è½¬æ¢ä¸ºé›†åˆä»¥ä¾¿äºå¿«é€ŸæŸ¥çœ‹ç”Ÿæˆçš„æ–°é¡¹ç›®æ˜¯å¦å·²ç»å­˜åœ¨
        closure_set = set()
        
        for item in items:
            if isinstance(item, dict):
                closure_set.add(self._dict_to_lr1_item(item))
            else:
                closure_set.add(item)

        changed = True

        while changed:
            changed = False
            for item in list(closure_set):
                # [A -> Î±.BÎ², a]
                # å¦‚æœç‚¹åœ¨äº§ç”Ÿå¼çš„å³ä¾§ï¼Œä¸”ç‚¹åè¿˜æœ‰ç¬¦å·
                if item.dot_pos < len(item.prod_rhs):
                    B = item.prod_rhs[item.dot_pos]
                    # å¯¹äºæ¯ä¸ªäº§ç”Ÿå¼B -> Î³ï¼Œæ·»åŠ åˆ°é—­åŒ…ä¸­
                    if B in self.non_terminals:
                        beta = item.prod_rhs[item.dot_pos+1:] # Î²
                        # è®¡ç®— FIRST(Î²a)
                        lookaheads = self.first(beta + (item.lookahead,)) if beta else {item.lookahead}
                        # æ·»åŠ æ–°é¡¹ç›®
                        for prod in self.productions[B]:
                            for la in lookaheads:
                                new_item = LR1Item(
                                    prod_lhs=B,
                                    prod_rhs=tuple(prod['rhs']),
                                    dot_pos=0,
                                    lookahead=la
                                )
                                if new_item not in closure_set:
                                    closure_set.add(new_item)
                                    changed = True

        # æ’åºé€»è¾‘ï¼šæŒ‰ prod_lhs â†’ prod_rhs â†’ dot_pos â†’ lookahead çš„ä¼˜å…ˆçº§
        sorted_items = sorted(
            closure_set,
            key=lambda x: (x.prod_lhs, x.prod_rhs, x.dot_pos, x.lookahead)
        )
        return tuple(sorted_items)
    
    def go(self, items, symbol):
        """
        çŠ¶æ€è½¬ç§»å‡½æ•°
        :param items: é¡¹ç›®é›†
        :param symbol: ç¬¦å·
        :return: è®¡ç®—è½¬ç§»åçš„é¡¹ç›®é›†(çŠ¶æ€)
        """
        new_items = set()

        for item in items:
            # å½“å‰çš„é¡¹ç›®Item
            current  =self._dict_to_lr1_item(item) if isinstance(item, dict) else item
            if current.dot_pos < len(current.prod_rhs) and current.prod_rhs[current.dot_pos] == symbol:
                new_item = LR1Item(
                    prod_lhs=current.prod_lhs,
                    prod_rhs=current.prod_rhs,
                    dot_pos=current.dot_pos + 1,  # ç§»åŠ¨ç‚¹ä½ç½®
                    lookahead=current.lookahead
                )
                new_items.add(new_item)

        return self.closure(new_items) if new_items else None
    
    def first(self, symbols, visited=None):
        """
        è®¡ç®—ç¬¦å·ä¸²çš„FIRSTé›†åˆ
        :param symbols: ç¬¦å·ä¸²
        :return: FIRSTé›†åˆ
        """
        if visited is None:
            visited = set()

        cache_key = tuple(symbols)
        if cache_key in self._first_cache:
            return self._first_cache[cache_key].copy()
        
        # æ£€æµ‹å¾ªç¯ä¾èµ–
        if cache_key in visited:
            return set()
        visited.add(cache_key)

        first_set = set()

        # å¤„ç†ç©ºä¸²''
        if not symbols:
            first_set.add('')
            return first_set
        
        for symbol in symbols:
            # å¤„ç†ç»ˆç»“ç¬¦
            if symbol in self.terminals or symbol == '$':
                first_set.add(symbol)
                first_set.discard('') # ç»ˆç»“ç¬¦ä¼šé˜»å¡Îµä¼ æ’­
                break
            
            # å¤„ç†éç»ˆç»“ç¬¦
            elif symbol in self.non_terminals:
                # ['A']
                has_epsilon = False # å‡è®¾FIRST(A)ä¸å­˜åœ¨Îµ ç”¨äºæ‹¦æˆªÎµ
                for prod in self.productions.get(symbol, []):
                    # A -> Îµ
                    if not prod['rhs']:
                        first_set.add('')
                        has_epsilon = True
                        continue
                    
                    # é€’å½’è®¡ç®—äº§ç”Ÿå¼å³éƒ¨çš„FIRSTé›†
                    # A -> B C D
                    sub_first = self.first(prod['rhs'], visited.copy())
                    first_set.update(sub_first - {''})

                    if '' in sub_first:
                        has_epsilon = True       
                                
                # è‹¥FIRST(A)çš„ä¸åŒ…å«Îµ éœ€è¦å°†Îµç§»é™¤å¹¶ä¸”éœ€è¦è·³å‡ºå¾ªç¯
                if not has_epsilon:
                    first_set.discard('')
                    break    
            
            # æœªçŸ¥ç±»å‹
            else :
                raise ValueError(f"æœªçŸ¥ç¬¦å·ç±»å‹: {symbol}")
            
        self._first_cache[cache_key] = first_set
        return first_set
    
    def build_parse_table(self, grammar):
        """
        æ„å»ºLR(1)åˆ†æè¡¨(ACTIONè¡¨å’ŒGOTOè¡¨)
        :return: åˆ†æè¡¨
        """
        self.grammar = grammar
        self._initialize_grammar()

        logger.debug("ğŸ› ï¸ å¼€å§‹æ„å»ºLR(1)åˆ†æè¡¨...")

        # åˆå§‹åŒ–åˆ†æè¡¨
        self.action_table = defaultdict(dict)
        self.goto_table = defaultdict(dict)
        self.states = []

        # ç”Ÿæˆåˆå§‹é¡¹ç›®é›†é—­åŒ…
        start_prod = self.productions[self.start_symbol][0]
        initial_item = LR1Item(
            prod_lhs=self.start_symbol,
            prod_rhs=tuple(start_prod['rhs']),
            dot_pos=0,
            lookahead='$'
        )
        
        # çŠ¶æ€
        initial_state = self.closure([initial_item]) # tuple(LR1Item)
        self.states = [initial_state]
        queue = [initial_state]
        state_ids = {initial_state: 0}

        # è®°å½•åˆå§‹çŠ¶æ€
        self._log_state_items(0, initial_state)

        while queue:
            current_state = queue.pop(0)
            current_id = state_ids[current_state] # è·å–çŠ¶æ€ç¼–å·
            logger.debug(f"å½“å‰å¤„ç†çŠ¶æ€ID:{current_id}")

            # éå†æ‰€æœ‰ç¬¦å·
            symbols = self.terminals.union(self.non_terminals)
            for idx, symbol in enumerate(symbols):
                new_state = self.go(current_state, symbol)
                if new_state and len(new_state) > 0:
                    if new_state not in state_ids:
                        new_state_id = len(self.states)
                        state_ids[new_state] = new_state_id
                        self.states.append(new_state)
                        queue.append(new_state)

                        # è®°å½•æ–°çŠ¶æ€çš„é¡¹ç›®é›†
                        self._log_state_items(new_state_id, new_state)

                    # è®°å½•è½¬ç§»åŠ¨ä½œ
                    new_state_id = state_ids[new_state]
                    if symbol in self.terminals:
                        # ç»ˆç»“ç¬¦ ACTIONè¡¨
                        self.action_table[current_id][symbol] = ('shift', new_state_id)
                    else:
                        # éç»ˆç»“ç¬¦ GOTOè¡¨
                        self.goto_table[current_id][symbol] = new_state_id
            
            # æ£€æŸ¥è§„çº¦é¡¹
            for item in current_state:
                if item.dot_pos == len(item.prod_rhs):
                    if item.prod_lhs == self.start_symbol and item.lookahead == '$':
                        # æ¥å—
                        self.action_table[current_id]['$'] = ('accept',)
                    else:
                        # è§„çº¦
                        for prod in self.productions[item.prod_lhs]:
                            if tuple(prod['rhs']) == item.prod_rhs:
                                self.action_table[current_id][item.lookahead] = ('reduce', prod['index'])
                                break

        logger.debug("âœ… åˆ†æè¡¨æ„å»ºå®Œæˆï¼ˆå…±%dä¸ªçŠ¶æ€ï¼‰" % len(self.states))
        return self.action_table, self.goto_table

    def analyse(self, tokens, checker: SemanticChecker = None):
        """
        æ‰§è¡ŒLR(1)è¯­æ³•åˆ†æ
        :param tokens: Tokenå¯¹è±¡åˆ—è¡¨
        :param checker: è¯­ä¹‰æ£€æŸ¥å™¨(æ˜¯å¦åœ¨è¯­æ³•åˆ†æè¿‡ç¨‹ä¸­è¿›è¡Œè¯­ä¹‰åˆ†æ)

        :return: (è¯­æ³•åˆ†ææ ‘æ ¹èŠ‚ç‚¹, åˆ†æè¿‡ç¨‹ä¿¡æ¯)
        """
        analysis_details = []         # åˆ†æè¿‡ç¨‹ä¿¡æ¯
        state_stack = [0]             # çŠ¶æ€æ ˆï¼Œåˆå§‹çŠ¶æ€ä¸º0
        node_stack = []               # èŠ‚ç‚¹æ ˆ
        idx = 0                       # å½“å‰tokenæŒ‡é’ˆ
        token_stream = list(tokens)   # tokenæµ
        
        while True:
            state = state_stack[-1]
            current_token = token_stream[idx]

            # è®°å½•å½“å‰çŠ¶æ€
            step_info = {
                "stack": list(state_stack),
                "node_stack": [str(n) for n in node_stack],
                "input": [str(t) for t in token_stream[idx:]],
                "action": "",
                "production": ""
            }
            
            # æŸ¥ACTIONè¡¨
            action = self.action_table[state].get(current_token.type.value)
            if not action:
                expected = sorted(self.action_table[state].keys())
                context = token_stream[max(0, idx-2):idx+1]
                raise SyntaxError(
                    f"è¯­æ³•é”™è¯¯ï¼ˆç¬¬{current_token.line}è¡Œ, ç¬¬{current_token.column}åˆ—ï¼‰\n"
                    f"æ„å¤–Token: {current_token}\n"
                    f"æœŸæœ›: {expected}\n"
                    f"ä¸Šä¸‹æ–‡: {context}"
                )
            
            # æ‰§è¡ŒåŠ¨ä½œ
            if action[0] == 'shift':
                step_info["action"] = f"ç§»å…¥: {current_token} -> çŠ¶æ€{action[1]}"

                # åˆ›å»ºç»ˆç»“ç¬¦èŠ‚ç‚¹
                new_node = ParseNode(symbol=current_token.type.value, children=None, token=current_token)
                node_stack.append(new_node)
                idx += 1

                # ACTIONè½¬ç§»
                action_state = action[1]
                state_stack.append(action_state)

            elif action[0] == 'reduce':
                prod_index = action[1]
                prod = self.prod_by_index[prod_index]
                lhs = prod['lhs']
                rhs_len = len(prod['rhs'])
                
                step_info["production"] = f"{lhs} â†’ {' '.join(prod['rhs']) if prod['rhs'] else 'Îµ' }" 
                step_info["action"] = f"è§„çº¦: åº”ç”¨äº§ç”Ÿå¼ {prod_index}"
                
                children = []
                if rhs_len > 0:
                    state_stack = state_stack[:-rhs_len]
                    children = node_stack[-rhs_len:]
                    node_stack = node_stack[:-rhs_len]
                
                # åˆ›å»ºéç»ˆç»“ç¬¦èŠ‚ç‚¹
                new_node = ParseNode(symbol=lhs, children=children)
                if checker:
                    checker.on_reduce(node=new_node)
                node_stack.append(new_node)

                # GOTOè½¬ç§»
                goto_state = self.goto_table[state_stack[-1]].get(lhs)
                if goto_state is None:
                    raise SyntaxError(f"æ— æ•ˆGOTOï¼šçŠ¶æ€{state_stack[-1]}é‡åˆ°{lhs}")
                state_stack.append(goto_state)

            elif action[0] == 'accept':
                step_info["action"] = "æ¥å—: åˆ†æå®Œæˆ"
                break
            
            else:
                raise SyntaxError(f"æ— æ•ˆåŠ¨ä½œ: {action}") 

            analysis_details.append(step_info)
            
        return node_stack[0], analysis_details
    
    def _dict_to_lr1_item(item_dict: dict) -> LR1Item:
        """
            å°†å­—å…¸å½¢å¼çš„é¡¹ç›®è½¬æ¢ä¸º LR1Item å¯¹è±¡
        Args:
            item_dict: å¿…é¡»åŒ…å«é”® 'production'ï¼ˆå« 'lhs' å’Œ 'rhs'ï¼‰ã€'dot_pos' å’Œ 'lookahead'ã€‚
        Returns:
            LR1Item: è½¬æ¢åçš„å‘½åå…ƒç»„å¯¹è±¡ã€‚
        """
        # æå–å¹¶éªŒè¯å­—æ®µ
        production = item_dict['production']
        lhs = production['lhs']
        rhs = tuple(production['rhs'])  # è½¬æ¢ä¸ºå…ƒç»„ä¿è¯å¯å“ˆå¸Œ
        dot_pos = item_dict['dot_pos']
        lookahead = item_dict['lookahead']

        return LR1Item(prod_lhs=lhs, prod_rhs=rhs, dot_pos=dot_pos, lookahead=lookahead)

    def _log_grammar_info(self):
        """è®°å½•è¯­æ³•åˆ†æè¯¦ç»†ä¿¡æ¯"""
        logger.debug("ğŸ” è¯­æ³•è§„åˆ™åˆ†æç»“æœ")
        logger.debug(f"èµ·å§‹ç¬¦å·: \033[1m{self.start_symbol}\033[0m")

        # ç¬¦å·ç»Ÿè®¡
        logger.debug(f"ç»ˆç»“ç¬¦({len(self.terminals)}): {', '.join(sorted(self.terminals))}")
        logger.debug(f"éç»ˆç»“ç¬¦({len(self.non_terminals)}): {', '.join(sorted(self.non_terminals))}")

        # äº§ç”Ÿå¼è¡¨æ ¼è¾“å‡º
        logger.debug("ğŸ“œ äº§ç”Ÿå¼è§„åˆ™:")
        max_lhs_len = max(len(lhs) for lhs in self.productions) if self.productions else 0
        for lhs in sorted(self.productions.keys()):
            for prod in self.productions[lhs]:
                rhs_str = ' '.join(prod['rhs']) if prod['rhs'] else "Îµ"
                logger.debug(f"  {lhs.ljust(max_lhs_len)} â†’ {rhs_str} \033[90m# {prod['index']}\033[0m")

    def _log_state_items(self, state_id, state):
        """è®°å½•çŠ¶æ€ä¸­çš„é¡¹ç›®é›†"""
        logger.debug(f"ğŸ” çŠ¶æ€ {state_id} é¡¹ç›®é›†:")
        for item in sorted(state, key=lambda x: (x.prod_lhs, x.prod_rhs, x.dot_pos)):
            # æ„å»ºå¸¦ç‚¹çš„äº§ç”Ÿå¼è¡¨ç¤º
            rhs = list(item.prod_rhs)
            rhs.insert(item.dot_pos, 'â€¢')
            production = f"{item.prod_lhs} â†’ {' '.join(rhs) if rhs else 'Îµ'}"

            # æ ¼å¼åŒ–è¾“å‡º
            logger.debug(f"  {production.ljust(40)} , {item.lookahead}")

if __name__ == "__main__":
    class TestTokenType(Enum):
        ID = 'id'
        EQUAL = '='
        END = '$'
    
    tokens = [
        Token(TestTokenType.ID, value="x", line=1, column=1),
        Token(TestTokenType.EQUAL, value="=", line=1, column=3),
        Token(TestTokenType.ID, value="y", line=1, column=5),
        Token(TestTokenType.END)
    ]
    parser_test = Parser(TEST_GRAMMAR)
    parser_test.parse(tokens)
    # æ¶ˆé™¤å·¦é€’å½’æµ‹è¯•
    parser_left_recursion = Parser(LEFT_RECURSION_GRAMMAR)
    pass


